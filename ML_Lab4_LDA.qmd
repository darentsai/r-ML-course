---
title: "Statistical and Machine Learning"
subtitle: "Lab4: Classification <br> Linear Discriminant Analysis"
author: "Tsai, Dai-Rong"
format:
  revealjs:
    theme: default
    echo: true
    smaller: true
    scrollable: true
    slide-number: true
    auto-stretch: false
    history: false
    pdf-max-pages-per-slide: 5
    embed-resources: true
tbl-cap-location: bottom
---

## Dataset

```{r echo = FALSE}
options(digits = 5, width = 100)
```

```{css echo = FALSE}
.reveal table, ul ul li{
  font-size: smaller;
}
```

> ***Edgar Anderson's Iris Data***

```{r}
# Set random seed
set.seed(12345)

# Packages
library(MASS) # for lda, qda
```

::: {layout-ncol=2}

- Response
    - `Species`: setosa / versicolor / virginica
- Predictors
    - `Sepal.Length`
    - `Sepal.Width`
    - `Petal.Length`
    - `Petal.Width`

```{r}
#| echo: false
#| fig-height: 10

caret::featurePlot(x = iris[1:4], y = iris$Species, plot = "ellipse",
                   auto.key = list(columns = 3))
```

:::

---

::: {.panel-tabset}

### Preview

```{r}
dim(iris)
head(iris)
proportions(table(iris$Species))
```

### Data Structure

```{r}
str(iris)
```

:::

## Create Training/Testing Partitions

- Split data into 80% training set and 20% test set

```{r}
nr <- nrow(iris)
train.id <- sample(nr, nr * 0.8)

training <- iris[train.id, ]
testing <- iris[-train.id, ]
```

- Check dimension

```{r}
dim(training)
dim(testing)
```

## Linear Discriminant Analysis (LDA)

```{r}
lda.mod <- lda(Species ~ ., training, prior = c(1,1,1)/3)
```

::: {.callout-note appearance="minimal"}

If `prior` is unspecified, the class proportions for the training set are used. If present, the probabilities should be specified in the order of the factor levels.

:::

::: {.callout-tip}

### Components of an `lda` object

- `prior`: the prior probabilities used.
- `means`: the group means.
- `scaling` : a matrix which transforms observations to discriminant functions, normalized so that within groups covariance matrix is spherical.
- `svd`: the singular values, which give the ratio of the between- and within-group standard deviations on the linear discriminant variables. Their squares are the canonical F-statistics.

:::

```{r echo = FALSE}
options(max.print = 20)
```

```{r}
lda.mod
```

```{r}
#| fig-width: 7

plot(lda.mod, col = as.integer(training$Species)+1, cex = 0.5)
```

---

- Retrieve the data used to fit the `lda` model

```{r}
lda.fit <- predict(lda.mod)
lda.fit
```

```{r}
#| fig-height: 10
#| layout-ncol: 2

ldahist(lda.fit$x[, 1], g = training$Species, type = "both"); title("LD1", cex.main = 2)
ldahist(lda.fit$x[, 2], g = training$Species, type = "both"); title("LD2", cex.main = 2)
```

- Computation of Linear Discriminants (`LDs`)

```{r}
(Z <- lda.mod$scaling)
X <- model.matrix(Species ~ ., training)[, -1]
center <- t(lda.mod$prior) %*% lda.mod$means
Xc <- scale(X, center = center, scale = FALSE)
LD <- Xc %*% Z
LD
all.equal(LD, lda.fit$x)
```

## Quadratic Discriminant Analysis (QDA)

```{r}
qda.mod <- qda(Species ~ ., training, prior = c(1,1,1)/3)
qda.mod
```

### Decision Boundaries

```{r}
#| fig-width: 7
#| code-fold: true
#| code-summary: "codes for plot"

library(ggplot2)

train.2d <- data.frame(lda.fit$x, Species = training$Species)
lda.2d.mod <- lda(Species ~ LD1 + LD2, train.2d)
qda.2d.mod <- qda(Species ~ LD1 + LD2, train.2d)

grid.2d <- expand.grid(lapply(train.2d[1:2], \(x) seq(min(x), max(x), length.out = 200)))
lda.post <- predict(lda.2d.mod, newdata = grid.2d)$posterior
qda.post <- predict(qda.2d.mod, newdata = grid.2d)$posterior
grid.2d.all <- cbind(grid.2d, LDA = lda.post, QDA = qda.post)

ggplot(train.2d, aes(x = LD1, y = LD2)) +
  geom_point(aes(fill = Species, shape = Species)) +
  geom_contour(aes(z = LDA.versicolor, colour = "LDA"), grid.2d.all, breaks = 0.5) +
  geom_contour(aes(z = QDA.versicolor, colour = "QDA"), grid.2d.all, breaks = 0.5) +
  scale_shape_manual(values = 22:24) +
  scale_colour_discrete(name = "Classifiers") +
  theme_bw()
```

## Prediction

```{r}
lda.pred <- predict(lda.mod, testing)
qda.pred <- predict(qda.mod, testing)
```

- LDA

```{r}
table(Reality = testing$Species, Prediction = lda.pred$class)
mean(testing$Species == lda.pred$class)
```

- QDA

```{r}
table(Reality = testing$Species, Prediction = qda.pred$class)
mean(testing$Species == qda.pred$class)
```
